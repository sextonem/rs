{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIE451/1513 UofT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MovieLens data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
    "\n",
    "* Upload ml-100k.zip\n",
    "\n",
    "* Extract using the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ml-100k.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\n",
      "allbut.pl\n",
      "mku.sh\n",
      "u.data\n",
      "u.genre\n",
      "u.info\n",
      "u.item\n",
      "u.occupation\n",
      "u.user\n",
      "u1.base\n",
      "u1.test\n",
      "u2.base\n",
      "u2.test\n",
      "u3.base\n",
      "u3.test\n",
      "u4.base\n",
      "u4.test\n",
      "u5.base\n",
      "u5.test\n",
      "ua.base\n",
      "ua.test\n",
      "ub.base\n",
      "ub.test\n"
     ]
    }
   ],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df.userID.unique())\n",
    "num_items = len(rating_df.itemID.unique())\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "    \"\"\"\n",
    "    ########### your code goes here ###########\n",
    "    ### no change from lab ???? confirm\n",
    "    # Initialize a of size (numUsers, numItems) to zeros\n",
    "    matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "    # Populate the matrix based on the dataset\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating\n",
    "    \n",
    "    \n",
    "    ###########         end         ###########\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "          # if rating == 0:\n",
    "            # Extract the items the user already rated\n",
    "            userVector = train_matrix[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "\n",
    "            # If not empty, calculate average and set as rating for the current item\n",
    "            if ratedItems.size == 0:\n",
    "                itemAvg = 0\n",
    "            else:\n",
    "                itemAvg = ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "            \n",
    "            #necessary???? REMOVE MAYBE?\n",
    "            # report progress every 100 users \n",
    "           # if (user % 100 == 0 and item == 1):\n",
    "            #    print (\"calculated %d users\" % (user,))\n",
    "\n",
    "\n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "        # For every item calculate the number of people liked (4-5) divided by the number of people that \n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        for item in range(num_items):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "           # if rating == 0:\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "\n",
    "            ##REMOVE???\n",
    "            # report progress every 100 users\n",
    "           # if (user % 100 == 0 and item == 1):\n",
    "            #    print (\"calculated %d users\" % (user,))\n",
    "\n",
    "                \n",
    "        ###########         end         ###########\n",
    "        #print(predictionMatrix)\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You don not have model..\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]\n",
      " [0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]\n",
      " [0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]\n",
      " [0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]\n",
      " [0.71017699 0.38931298 0.37777778 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "popularity_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = popularity_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(x<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:30, 1107.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.804714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  popularity\n",
       "0     196     242       3  881250949    0.760684\n",
       "1     186     302       3  891717742    0.804714\n",
       "2      22     377       1  878887116    0.076923\n",
       "3     244      51       2  880606923    0.555556\n",
       "4     166     346       1  886397596    0.611111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61029412, 3.61029412, 3.61029412, ..., 3.61029412, 3.61029412,\n",
       "        3.61029412],\n",
       "       [3.70967742, 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
       "        3.70967742],\n",
       "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
       "        2.7962963 ],\n",
       "       ...,\n",
       "       [4.04545455, 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
       "        4.04545455],\n",
       "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
       "        4.26582278],\n",
       "       [3.41071429, 3.41071429, 3.41071429, ..., 3.41071429, 3.41071429,\n",
       "        3.41071429]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:25, 1171.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>useraverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.413043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>3.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  useraverage\n",
       "0     196     242       3  881250949     3.615385\n",
       "1     186     302       3  891717742     3.413043\n",
       "2      22     377       1  878887116     3.351562\n",
       "3     244      51       2  880606923     3.651261\n",
       "4     166     346       1  886397596     3.550000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "\n",
    "        similarity_matrix = 1 /(1 + pairwise_distances(matrix, metric='euclidean'))\n",
    "    \n",
    "        ###########         end         ###########    \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix): ##gotta fix this puppy up\n",
    "        \"\"\"\n",
    "            manhattan? or super-natural intuition similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "        \n",
    "        similarity_matrix = 1/ (1 +pairwise_distances(matrix, metric='manhattan'))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "        ###########         end         ###########        \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        if self.base == 'user':\n",
    "            ########### your code goes here ###########\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            temp_matrix[temp_matrix == 0] = 1e-5\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "            #if k is not None:\n",
    "            #    uu_similarity = kNearestNeighbor(uu_similarity, k)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer #matches key line in func above but vectorized bb\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "\n",
    "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "            self.__model = predictionMatrix\n",
    "\n",
    "            ###########         end         ###########\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            ########### your code goes here ###########\n",
    "            train_matrixT = train_matrix.transpose()\n",
    "            temp_matrix = np.zeros(train_matrixT.shape)\n",
    "            temp_matrix[train_matrixT.nonzero()] = 1\n",
    "            temp_matrix[temp_matrix == 0] = 1e-5\n",
    "            \n",
    "            ii_similarity = self.method(train_matrixT)\n",
    "            #if k is not None: \n",
    "            #    ii_similarity = kNearestNeighbor(ii_similarity, k)\n",
    "            normalizer = np.matmul(ii_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(ii_similarity, train_matrixT)/normalizer #matches key line in func above but vectorized bb\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "\n",
    "            itemaverage = np.sum(train_matrixT, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "            self.__model = predictionMatrix.transpose()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            ###########         end         ###########\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of how to call similarity functions.\n",
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.41421356, 0.41421356],\n",
       "       [0.41421356, 1.        , 0.41421356],\n",
       "       [0.41421356, 0.41421356, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.euclidean(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.33333333],\n",
       "       [0.33333333, 1.        , 0.33333333],\n",
       "       [0.33333333, 0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.somethingelse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity works best, this is because it cares about the angles between the vectors, not the length of the vectors(normalized for length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented manhattan (after trying jaccard to relative failure), I think this could be a good similarity metric because ( since it is same as city block or l1) because it handles sparseness, which in general exists in user ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       ...,\n",
       "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:26, 1153.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>4.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.142828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1.922080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.431884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.424963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  user-cosine\n",
       "0     196     242       3  881250949     4.025213\n",
       "1     186     302       3  891717742     4.142828\n",
       "2      22     377       1  878887116     1.922080\n",
       "3     244      51       2  880606923     3.431884\n",
       "4     166     346       1  886397596     3.424963"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use CrossValidation Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "#algorithm_instances = [popularity_recsys, \n",
    "#                       average_user_rating_recsys, \n",
    "#                       user_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
    "# RMSE, P@K, R@K\n",
    "# Precision at K in this example\n",
    "cv_patk = CrossValidation('P@K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Run CV by giving:\n",
    "#    1> algorithms just gathered\n",
    "#    2> number of users in the full dataset\n",
    "#    3> number of items in the full dataset\n",
    "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
    "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
    "#cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75429099, 3.66419957, 3.73222997, ..., 3.60248287, 3.79662696,\n",
       "        3.90232044],\n",
       "       [3.83658867, 3.80424519, 3.77473905, ..., 3.72798332, 3.9109779 ,\n",
       "        3.79775927],\n",
       "       [2.84492718, 2.89389328, 2.84327324, ..., 2.99504451, 3.16444153,\n",
       "        2.9858119 ],\n",
       "       ...,\n",
       "       [4.11427954, 4.0558267 , 4.00963139, ..., 4.        , 3.87872799,\n",
       "        4.14814803],\n",
       "       [4.37096823, 4.39679254, 4.33543016, ..., 3.955358  , 4.41891089,\n",
       "        4.57995134],\n",
       "       [3.52030345, 3.46948821, 3.52393064, ..., 0.        , 3.6110641 ,\n",
       "        3.59656861]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:32, 1079.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.591314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.344077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2.965365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.637332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.333013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  item-cosine\n",
       "0     196     242       3  881250949     3.591314\n",
       "1     186     302       3  891717742     3.344077\n",
       "2      22     377       1  878887116     2.965365\n",
       "3     244      51       2  880606923     3.637332\n",
       "4     166     346       1  886397596     3.333013"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_instances = [item_cosine_recsys,  \n",
    "                       user_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rmse = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-rs\\lib\\site-packages\\ipykernel\\__main__.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:14, 1405.28it/s]\n",
      "20000it [00:13, 1429.90it/s]\n",
      "20000it [00:14, 1427.45it/s]\n",
      "20000it [00:14, 1403.90it/s]\n",
      "20000it [00:14, 1396.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1434.82it/s]\n",
      "20000it [00:14, 1426.33it/s]\n",
      "20000it [00:14, 1404.10it/s]\n",
      "20000it [00:14, 1382.93it/s]\n",
      "20000it [00:13, 1446.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [[1.0377631264364244,\n",
       "   1.0207280585350078,\n",
       "   1.0101820660011798,\n",
       "   1.0136832839209695,\n",
       "   1.0180579656376574],\n",
       "  1.020082900106248,\n",
       "  1.0068242686250732,\n",
       "  1.0333415315874226],\n",
       " 'user-cosine': [[1.026449013124381,\n",
       "   1.0214387664779507,\n",
       "   1.0132940326457187,\n",
       "   1.0094003999022947,\n",
       "   1.0161883961525586],\n",
       "  1.0173541216605808,\n",
       "  1.009013080226148,\n",
       "  1.0256951630950135]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse.run(algorithm_instances, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) There is no statistically significant better performer, however user-user similarity does perform slightly better.  For this case, if we to run more (k>5) cross validations, we would expect it to be statistically better, because in this data set we have on average 106 ratings per user and only 59 average ratings per item.  Therefore, we have more information about the users than the items.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_instances = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ratk = CrossValidation('R@K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "[[0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1408.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1419.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1504.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1505.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1518.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1435.03it/s]\n",
      "20000it [00:14, 1399.19it/s]\n",
      "20000it [00:14, 1420.96it/s]\n",
      "20000it [00:14, 1397.92it/s]\n",
      "20000it [00:16, 1222.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1214.04it/s]\n",
      "20000it [00:16, 1196.61it/s]\n",
      "20000it [00:17, 1125.82it/s]\n",
      "20000it [00:17, 1175.16it/s]\n",
      "20000it [00:13, 1471.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-rs\\lib\\site-packages\\ipykernel\\__main__.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:13, 1481.16it/s]\n",
      "20000it [00:14, 1402.63it/s]\n",
      "20000it [00:15, 1285.02it/s]\n",
      "20000it [00:14, 1352.72it/s]\n",
      "20000it [00:15, 1311.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [[0.34316012725344736,\n",
       "   0.483563096500532,\n",
       "   0.6021208907741271,\n",
       "   0.6248144220572649,\n",
       "   0.6074231177094392],\n",
       "  0.5322163308589621,\n",
       "  0.3837005215009889,\n",
       "  0.6807321402169354],\n",
       " 'popularity': [[0.36924708377518656,\n",
       "   0.4965005302226948,\n",
       "   0.6152704135737019,\n",
       "   0.6426299045599162,\n",
       "   0.6292682926829279],\n",
       "  0.5505832449628855,\n",
       "  0.40544114481568705,\n",
       "  0.6957253451100839],\n",
       " 'user-cosine': [[0.37179215270413657,\n",
       "   0.503923647932133,\n",
       "   0.621633085896077,\n",
       "   0.6483563096500541,\n",
       "   0.6335100742311777],\n",
       "  0.5558430540827157,\n",
       "  0.40959849499983714,\n",
       "  0.7020876131655943],\n",
       " 'useraverage': [[0.30604453870625714,\n",
       "   0.4305408271474029,\n",
       "   0.5321314952279973,\n",
       "   0.5520678685047737,\n",
       "   0.5474019088016986],\n",
       "  0.4736373276776259,\n",
       "  0.3419993013451059,\n",
       "  0.6052753540101459]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "[[0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1404.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1424.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1412.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1400.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1460.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1419.14it/s]\n",
      "20000it [00:13, 1448.86it/s]\n",
      "20000it [00:13, 1514.00it/s]\n",
      "20000it [00:14, 1376.94it/s]\n",
      "20000it [00:14, 1378.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1405.19it/s]\n",
      "20000it [00:14, 1401.54it/s]\n",
      "20000it [00:16, 1229.26it/s]\n",
      "20000it [00:16, 1239.08it/s]\n",
      "20000it [00:15, 1255.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-rs\\lib\\site-packages\\ipykernel\\__main__.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1318.57it/s]\n",
      "20000it [00:15, 1325.38it/s]\n",
      "20000it [00:15, 1305.40it/s]\n",
      "20000it [00:15, 1332.62it/s]\n",
      "20000it [00:15, 1270.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [[0.3277711938444533,\n",
       "   0.4237782250680911,\n",
       "   0.5191391022223312,\n",
       "   0.5448659224612776,\n",
       "   0.5593011306991799],\n",
       "  0.4749711148590666,\n",
       "  0.35357317503649865,\n",
       "  0.5963690546816346],\n",
       " 'popularity': [[0.3466588624187514,\n",
       "   0.4274468698270901,\n",
       "   0.5269205125667804,\n",
       "   0.5518738761026849,\n",
       "   0.5674793185065369],\n",
       "  0.4840758878843688,\n",
       "  0.3671373629798323,\n",
       "  0.6010144127889052],\n",
       " 'user-cosine': [[0.34778041993806913,\n",
       "   0.4314035774468209,\n",
       "   0.5293633772333985,\n",
       "   0.5553818201403046,\n",
       "   0.5674144230096255],\n",
       "  0.4862687235536437,\n",
       "  0.3694473610987218,\n",
       "  0.6030900860085656],\n",
       " 'useraverage': [[0.30505841002027845,\n",
       "   0.39554692074366876,\n",
       "   0.48030412192442223,\n",
       "   0.5045885853815734,\n",
       "   0.5211179870422066],\n",
       "  0.44132320502242983,\n",
       "  0.32931026359142457,\n",
       "  0.5533361464534351]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ratk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "[[0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]\n",
      " [0.71018277 0.38095238 0.37333333 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:17, 1165.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]\n",
      " [0.71787709 0.40186916 0.36923077 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1244.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]\n",
      " [0.70655271 0.39449541 0.42666667 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1200.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]\n",
      " [0.71745152 0.38613861 0.375      ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1374.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]\n",
      " [0.69859155 0.38235294 0.34246575 ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1374.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1267.19it/s]\n",
      "20000it [00:14, 1334.58it/s]\n",
      "20000it [00:14, 1384.94it/s]\n",
      "20000it [00:14, 1366.21it/s]\n",
      "20000it [00:14, 1391.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1406.07it/s]\n",
      "20000it [00:14, 1399.97it/s]\n",
      "20000it [00:14, 1394.51it/s]\n",
      "20000it [00:14, 1384.66it/s]\n",
      "20000it [00:14, 1371.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-rs\\lib\\site-packages\\ipykernel\\__main__.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:14, 1384.85it/s]\n",
      "20000it [00:14, 1395.58it/s]\n",
      "20000it [00:14, 1387.35it/s]\n",
      "20000it [00:14, 1391.98it/s]\n",
      "20000it [00:14, 1386.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [[1.0377631264364244,\n",
       "   1.0207280585350078,\n",
       "   1.0101820660011798,\n",
       "   1.0136832839209695,\n",
       "   1.0180579656376574],\n",
       "  1.020082900106248,\n",
       "  1.0068242686250732,\n",
       "  1.0333415315874226],\n",
       " 'popularity': [[3.177941281084362,\n",
       "   3.1750480150769977,\n",
       "   3.147474655005899,\n",
       "   3.146164503024159,\n",
       "   3.1488360007536382],\n",
       "  3.1590928909890112,\n",
       "  3.139292746995387,\n",
       "  3.1788930349826354],\n",
       " 'user-cosine': [[1.026449013124381,\n",
       "   1.0214387664779507,\n",
       "   1.0132940326457187,\n",
       "   1.0094003999022947,\n",
       "   1.0161883961525586],\n",
       "  1.0173541216605808,\n",
       "  1.009013080226148,\n",
       "  1.0256951630950135],\n",
       " 'useraverage': [[1.0629951276561334,\n",
       "   1.0467467492319966,\n",
       "   1.0328964562995389,\n",
       "   1.0366575971298078,\n",
       "   1.0392923504800367],\n",
       "  1.0437176561595025,\n",
       "  1.0289303496379316,\n",
       "  1.0585049626810734]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse.run(algorithm_instances, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| P@K |  Mean   |  CI   |\n",
    "|------|------|-------|\n",
    "|  ii-sim  | 0.53 | [0.38,0.68] |\n",
    "|  uu-sim  | 0.56 | [0.41,0.70] |\n",
    "|  user avg  | 0.47 | [0.34,0.60] |\n",
    "|  pop  | 0.55 | [0.41,0.70] |\n",
    "\n",
    "| R@K |  Mean   |  CI   |\n",
    "|------|------|-------|\n",
    "|  ii-sim  | 0.47 | [0.35,0.59] |\n",
    "|  uu-sim  | 0.49 | [0.37,0.60] |\n",
    "|  user avg  | 0.44 | [0.33,0.55] |\n",
    "|  pop  | 0.48 | [0.37,0.60] |\n",
    "\n",
    "| RMSE |  Mean   |  CI   |\n",
    "|------|------|-------|\n",
    "|  ii-sim  | 1.020 | [1.007,1.033] |\n",
    "|  uu-sim  | 1.017 | [1.009,1.026] |\n",
    "|  user avg  | 1.044 | [1.029,1.059] |\n",
    "|  pop  | 3.159 | [3.139,3.179] |\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "popularity can not necessarily be evaluated based on RMSE.  This  is because popularity cares about the ranking of a movie (do more users like it than dislike it), whereas the other metrics create a rating that is based around the ratings of other users (either by average, or similarity).  This makes RMSE which is evaluating the distance from the actual rating to the predicted rating not very useful, as the popularity is calculated using a different scale.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: uu-sim - this is bc it is mean centric (probability based on average of users around you unlike pop), and has most descriptive & personalized information (more rankings users than items, more personalized than user average). \n",
    "R@K: uu-sim - same as above\n",
    "P@K: uu-sim - same as above\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good performance on RMSE implies good performance on ranking metrics bc, if RMSE is low, that means the predictions have low deviation from the true ratings, and therefore you are likely to have a similar ranking order (since you rank by rating).  Hi ranking results however do not imply good RSME, because you may be able to get the top 5 results correct (have correct ranking), but your ratings could be far off from the true ratings (ex if true top 3 have these IDs and ratings: 1:5, 2:4.9, 3:4.5, and predicted top 3 have: 1:.9, 2:.85, 3:.8, the ranking is correct, but the ratings are hugely different from the true ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def userTopK(prediction, moviesDataset, userID, k):\n",
    "#    # Pick top K based on predicted rating\n",
    "#    userVector = prediction[userID+1,:]\n",
    "#    topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "#    namesTopK = list(map(lambda x: moviesDataset[moviesDataset.movieID == x+1][\"movieTitle\"].values[0], topK))\n",
    " #   return namesTopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
    "\n",
    "\n",
    "#moviesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#userTopK(user_cosine_recsys.getModel(), moviesDF, 144, 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Princess Bride, The (1987)'\n",
    "#'Wizard of Oz, The (1939)'\n",
    "#'Rear Window (1954)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemTopK(prediction, moviesDataset, movieTitle, k):\n",
    "    # Pick top K based on predicted rating\n",
    "    index = moviesDF.index[moviesDF['movieTitle'] == movieTitle].values\n",
    "    itemVector = prediction[:, index]\n",
    "    topK = nlargest(k+1, range(len(itemVector)), itemVector.take)\n",
    "    topK = topK[1:k+1]\n",
    "    namesTopK = list(map(lambda x: moviesDataset[moviesDataset.movieID == x+1][\"movieTitle\"].values[0], topK))\n",
    "    return namesTopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cosine_recsys2 = SimBasedRecSys('item','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.68717082, 0.82397582, 0.86639358],\n",
       "       [0.68717082, 1.        , 0.71691882, 0.78964707],\n",
       "       [0.82397582, 0.71691882, 1.        , 0.95268874],\n",
       "       [0.86639358, 0.78964707, 0.95268874, 1.        ]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys2.cosine(rating_df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itemTopK(item_cosine_recsys.getModel(), moviesDF, 'Princess Bride, The (1987)', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix2 = item_cosine_recsys2.processor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Raiders of the Lost Ark (1981)',\n",
       " 'Empire Strikes Back, The (1980)',\n",
       " 'Monty Python and the Holy Grail (1974)',\n",
       " 'Back to the Future (1985)',\n",
       " 'Indiana Jones and the Last Crusade (1989)']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemTopK(item_cosine_recsys2.cosine(train_matrix2.transpose()), moviesDF, 'Princess Bride, The (1987)', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E.T. the Extra-Terrestrial (1982)',\n",
       " 'Forrest Gump (1994)',\n",
       " 'Gone with the Wind (1939)',\n",
       " \"It's a Wonderful Life (1946)\",\n",
       " 'Raiders of the Lost Ark (1981)']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemTopK(item_cosine_recsys2.cosine(train_matrix.transpose()), moviesDF, 'Wizard of Oz, The (1939)', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Vertigo (1958)',\n",
       " 'Psycho (1960)',\n",
       " 'Casablanca (1942)',\n",
       " 'Sting, The (1973)',\n",
       " 'Graduate, The (1967)']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemTopK(item_cosine_recsys2.cosine(train_matrix.transpose()), moviesDF, 'Rear Window (1954)', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incase the autograder destroys me:\n",
    "movie: princess bride |\n",
    "similar movies: ['Raiders of the Lost Ark (1981)',\n",
    " 'Empire Strikes Back, The (1980)',\n",
    " 'Monty Python and the Holy Grail (1974)',\n",
    " 'Back to the Future (1985)',\n",
    " 'Indiana Jones and the Last Crusade (1989)']\n",
    "    movie: wizard of oz |\n",
    "similar movies: ['E.T. the Extra-Terrestrial (1982)',\n",
    " 'Forrest Gump (1994)',\n",
    " 'Gone with the Wind (1939)',\n",
    " \"It's a Wonderful Life (1946)\",\n",
    " 'Raiders of the Lost Ark (1981)']\n",
    "     movie: rear window |\n",
    " similar movies:['Vertigo (1958)',\n",
    " 'Psycho (1960)',\n",
    " 'Casablanca (1942)',\n",
    " 'Sting, The (1973)',\n",
    " 'Graduate, The (1967)']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELL YES I CAN JUSTIFY THE SIMILARITIES, just look at them ^^^^^^^^^\n",
    "-for each movie, the related titles follow either the era, genre, director, etc.  it makes sense that these titles appear bc it shows that users tend to watch and rate similar movies similarly BOOM this question took me WAY longer than it shouldve you sneaky cosine similarity you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 [GRAD ONLY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validateDataPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    popularity_recsys = BaseLineRecSys('popularity')\n",
    "    try:\n",
    "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except Exception as e:        \n",
    "        print('popularity function has error')\n",
    "        print(e)\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = popularity_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Average Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    useraverage_recsys = BaseLineRecSys('average_user_rating')\n",
    "    try:\n",
    "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print('useraverage function has error')\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = useraverage_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]\n",
      " [0.71014493 0.42307692 0.4        ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similary Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Similarity Function (test somethingelse function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateCustomizedSim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateUUSimBasedRecSys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Item Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateIISimBasedRecSys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
